import os
import json
import subprocess
import asyncio
import time
from pathlib import Path
from typing import List, Dict

import groq
from tqdm import tqdm
from groq_client import client
from config import settings


class MatchProcessor:
    def __init__(self, input_file: str, output_dir: str = "./match_data"):
        self.input_file = Path(input_file)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.chunk_len = 300  # 5 –º–∏–Ω—É—Ç (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)

    def split_audio(self) -> List[Path]:
        """–†–µ–∂–µ—Ç –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ –Ω–∞ –∫—É—Å–∫–∏ –ø–æ 5 –º–∏–Ω—É—Ç —á–µ—Ä–µ–∑ ffmpeg"""
        print(f"üî™ –ù–∞—Ä–µ–∑–∞–µ–º {self.input_file.name} –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã...")

        segment_pattern = self.output_dir / "part_%03d.mp3"

        # ffmpeg –∫–æ–º–∞–Ω–¥–∞: –±–µ—Ä–µ–º –∞—É–¥–∏–æ, —Ä–µ–∂–µ–º –Ω–∞ –∫—É—Å–∫–∏, –∫–æ–¥–∏—Ä—É–µ–º –≤ –ª–µ–≥–∫–∏–π mp3
        cmd = [
            "ffmpeg", "-y", "-i", str(self.input_file),
            "-f", "segment", "-segment_time", str(self.chunk_len),
            "-c:a", "libmp3lame", "-q:a", "4",  # –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –º–∞–ª—ã–π –≤–µ—Å
            "-vn",  # –ë–µ–∑ –≤–∏–¥–µ–æ
            "-loglevel", "error",
            str(segment_pattern)
        ]
        subprocess.run(cmd, check=True)

        # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        return sorted(self.output_dir.glob("part_*.mp3"))

    def transcribe_chunk(self, file_path: Path) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫—É—Å–æ–∫ –≤ Groq Whisper"""
        try:
            with open(file_path, "rb") as f:
                return client.audio.transcriptions.create(
                    file=f,
                    model=settings.WHISPER_MODEL,
                    language="ru",
                    response_format="text"
                )
        except groq.RateLimitError:
            print('limit, wait 3 min')
            time.sleep(180)
            with open(file_path, "rb") as f:
                return client.audio.transcriptions.create(
                    file=f,
                    model=settings.WHISPER_MODEL,
                    language="ru",
                    response_format="text"
                )


    def analyze_text(self, text: str, chunk_index: int) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è"""
        start_time = chunk_index * self.chunk_len // 60
        end_time = (chunk_index + 1) * self.chunk_len // 60
        time_range = f"{start_time}-{end_time} –º–∏–Ω"

        prompt = f"""
        –¢—ã ‚Äî —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –º–∞—Ç—á–∞ ({time_range}) 
        –∏ –∏–∑–≤–ª–µ—á—å –¢–û–õ–¨–ö–û –∫–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON. –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.

        –¢–µ–∫—Å—Ç:
        "{text}"

        –ü—Ä–∞–≤–∏–ª–∞:
        1. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –≤–æ–¥—É, –∏—Å—Ç–æ—Ä–∏—é –∏–≥—Ä–æ–∫–æ–≤, –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ–≥–æ–¥—ã.
        2. –ò—â–∏: –ì–æ–ª—ã, –û–ø–∞—Å–Ω—ã–µ —É–¥–∞—Ä—ã, –ö–∞—Ä—Ç–æ—á–∫–∏, –ó–∞–º–µ–Ω—ã, –¢—Ä–∞–≤–º—ã, VAR.
        3. –ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏–π –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.
        4. –§–æ—Ä–º–∞—Ç JSON: {{ "events": [ {{ "time": "—Ç–æ—á–Ω–æ–µ –≤—Ä–µ–º—è", "event": "–û–ø–∏—Å–∞–Ω–∏–µ" }} ] }}
        """

        try:
            chat_completion = client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=settings.LLM_MODEL,
                response_format={"type": "json_object"}
            )
            return json.loads(chat_completion.choices[0].message.content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {"events": []}

    def process(self):
        # 1. –ù–∞—Ä–µ–∑–∫–∞
        chunks = self.split_audio()
        full_report = []

        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(chunks)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")

        # 2. –¶–∏–∫–ª –ø–æ –∫—É—Å–∫–∞–º
        for i, chunk_path in enumerate(tqdm(chunks, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Ç—á–∞")):
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
            text = self.transcribe_chunk(chunk_path)

            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –º—É—Å–æ—Ä–Ω—ã–π - —Å–∫–∏–ø–∞–µ–º
            if len(text) < 10:
                continue

            # –ê–Ω–∞–ª–∏–∑
            analysis = self.analyze_text(text, i)

            if analysis.get("events"):
                full_report.extend(analysis["events"])
                # –°—Ä–∞–∑—É –≤—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
                for evt in analysis["events"]:
                    print(f"‚öΩ [{evt.get('time', '?')}] {evt.get('event')}")

        # 3. –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self.save_report(full_report)

    def save_report(self, events):
        report_path = self.output_dir / "final_report.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(events, f, ensure_ascii=False, indent=2)
        print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_path}")


# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    # –£–∫–∞–∂–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –º–∞—Ç—á–µ–º (–≤–∏–¥–µ–æ –∏–ª–∏ –∞—É–¥–∏–æ)
    # –ú–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å —Å YouTube –ª—é–±–æ–π –æ–±–∑–æ—Ä –Ω–∞ 10-15 –º–∏–Ω—É—Ç –¥–ª—è —Ç–µ—Å—Ç–∞
    processor = MatchProcessor("match_video.mp4")
    processor.process()